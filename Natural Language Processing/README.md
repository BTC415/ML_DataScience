# Natural Language Processing

This section presents a list of `resources` aimed at those who want to start or continue their `Natural Language Processing` journey! The topic overview takes insipration by the Deep Natural Language Processing course yield at [Politecnico di Torino](https://didattica.polito.it/pls/portal30/gap.pkg_guide.viewGap?p_cod_ins=01VIXSM&p_a_acc=2022&p_header=S&p_lang=&multi=N) by Professor Luca Cagliero and Dr. Moreno La Quatra.

---

### Table of contents

* [Intro of Natural Language Processing](#intronlp) 
* [Books](#books)
* [Topic Modeling](#topic_modeling)
* [Word Embeddings](#word_embeddings)
* [Contextualized Embeddings](#contextualized_embeddings)

---

<a name="intronlp"/>

### Intro of Natural Language Processing
* [What is Natural Language Processing](https://machinelearningmastery.com/natural-language-processing/)
* [NLP vs NLU vs NLG](https://www.ibm.com/blogs/watson/2020/11/nlp-vs-nlu-vs-nlg-the-differences-between-three-natural-language-processing-concepts/)
* [NLP Tasks](https://monkeylearn.com/natural-language-processing/)
* [Text representation](https://towardsdatascience.com/introduction-to-text-representations-for-language-processing-part-1-dc6e8068b8a4)
* [Text preprocessing](https://towardsdatascience.com/effectively-pre-processing-the-text-data-part-1-text-cleaning-9ecae119cb3e)

---

<a name="books" />

### Books
* [Natural Language Processing in Action: Understanding, Analyzing, and Generating Text with Python](https://www.amazon.it/Natural-Language-Processing-Action-Understanding/dp/1617294632)

---

<a name="topic_modeling" />

### Topic Modeling
* [What is Topic Modeling](https://en.wikipedia.org/wiki/Topic_model)
* [Latent Dirichlet Allocation](https://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf) (theory)
* [Latent Dirichlet Allocation](https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24) (python)
* [Latent Semantic Analysis via SVD and NMF](https://www.youtube.com/watch?v=tG3pUwmGjsc&list=PLtmWHNX-gukKocXQOkQjuVxglSDYWsSh9&index=19)
* [Randomized SVD](https://gregorygundersen.com/blog/2019/01/17/randomized-svd/)
* [Author Topic Modeling](https://mimno.infosci.cornell.edu/info6150/readings/398.pdf) (paper)
* [Author Topic Modeling](https://nbviewer.org/github/rare-technologies/gensim/blob/develop/docs/notebooks/atmodel_tutorial.ipynb) (notebook)


<a name="word_embeddings" />

### Word Embeddings
* [Word Embeddings](https://machinelearningmastery.com/what-are-word-embeddings/)
* [Word2Vec](https://jalammar.github.io/illustrated-word2vec/)
* [FastText](https://towardsdatascience.com/fasttext-under-the-hood-11efc57b2b3)
* [GloVe](https://nlp.stanford.edu/projects/glove/)

<a name="contextualized_embeddings" />

### Contextualized Embeddings
* [Word Embeddings vs Contextualized Word Embeddings](https://stackoverflow.com/questions/62272056/what-are-the-differences-between-contextual-embedding-and-word-embedding)
* [TagLM](https://shubhamg.in/nlp/language_model/review/2020/04/23/tag-lm.html)
* [ELMo](https://www.youtube.com/watch?v=YZerhaFMPTw)
* [The Illustrated BERT, ELMo, and co.](https://jalammar.github.io/illustrated-bert/)
